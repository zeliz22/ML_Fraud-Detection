{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":14242,"databundleVersionId":568274,"sourceType":"competition"}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-25T12:23:47.229564Z","iopub.execute_input":"2025-04-25T12:23:47.229997Z","iopub.status.idle":"2025-04-25T12:23:47.240138Z","shell.execute_reply.started":"2025-04-25T12:23:47.229973Z","shell.execute_reply":"2025-04-25T12:23:47.239171Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/ieee-fraud-detection/sample_submission.csv\n/kaggle/input/ieee-fraud-detection/test_identity.csv\n/kaggle/input/ieee-fraud-detection/train_identity.csv\n/kaggle/input/ieee-fraud-detection/test_transaction.csv\n/kaggle/input/ieee-fraud-detection/train_transaction.csv\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"!pip install dagshub mlflow","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T12:23:47.244122Z","iopub.execute_input":"2025-04-25T12:23:47.244477Z","iopub.status.idle":"2025-04-25T12:23:52.027527Z","shell.execute_reply.started":"2025-04-25T12:23:47.244453Z","shell.execute_reply":"2025-04-25T12:23:52.026195Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: dagshub in /usr/local/lib/python3.11/dist-packages (0.5.9)\nRequirement already satisfied: mlflow in /usr/local/lib/python3.11/dist-packages (2.22.0)\nRequirement already satisfied: PyYAML>=5 in /usr/local/lib/python3.11/dist-packages (from dagshub) (6.0.2)\nRequirement already satisfied: appdirs>=1.4.4 in /usr/local/lib/python3.11/dist-packages (from dagshub) (1.4.4)\nRequirement already satisfied: click>=8.0.4 in /usr/local/lib/python3.11/dist-packages (from dagshub) (8.1.8)\nRequirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from dagshub) (0.28.1)\nRequirement already satisfied: GitPython>=3.1.29 in /usr/local/lib/python3.11/dist-packages (from dagshub) (3.1.44)\nRequirement already satisfied: rich>=13.1.0 in /usr/local/lib/python3.11/dist-packages (from dagshub) (14.0.0)\nRequirement already satisfied: dacite~=1.6.0 in /usr/local/lib/python3.11/dist-packages (from dagshub) (1.6.0)\nRequirement already satisfied: tenacity>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from dagshub) (9.0.0)\nRequirement already satisfied: gql[requests] in /usr/local/lib/python3.11/dist-packages (from dagshub) (3.5.2)\nRequirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from dagshub) (0.6.7)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from dagshub) (2.2.3)\nRequirement already satisfied: treelib>=1.6.4 in /usr/local/lib/python3.11/dist-packages (from dagshub) (1.7.1)\nRequirement already satisfied: pathvalidate>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from dagshub) (3.2.3)\nRequirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from dagshub) (2.9.0.post0)\nRequirement already satisfied: boto3 in /usr/local/lib/python3.11/dist-packages (from dagshub) (1.37.29)\nRequirement already satisfied: semver in /usr/local/lib/python3.11/dist-packages (from dagshub) (3.0.4)\nRequirement already satisfied: dagshub-annotation-converter>=0.1.5 in /usr/local/lib/python3.11/dist-packages (from dagshub) (0.1.9)\nRequirement already satisfied: mlflow-skinny==2.22.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.22.0)\nRequirement already satisfied: Flask<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.1.0)\nRequirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.1.6)\nRequirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.15.2)\nRequirement already satisfied: docker<8,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (7.1.0)\nRequirement already satisfied: graphene<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.4.3)\nRequirement already satisfied: gunicorn<24 in /usr/local/lib/python3.11/dist-packages (from mlflow) (23.0.0)\nRequirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.7)\nRequirement already satisfied: matplotlib<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.7.5)\nRequirement already satisfied: numpy<3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.26.4)\nRequirement already satisfied: pyarrow<20,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (19.0.1)\nRequirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.2.2)\nRequirement already satisfied: scipy<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.15.2)\nRequirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.0.38)\nRequirement already satisfied: cachetools<6,>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (5.5.2)\nRequirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (3.1.1)\nRequirement already satisfied: databricks-sdk<1,>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (0.50.0)\nRequirement already satisfied: fastapi<1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (0.115.12)\nRequirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (8.6.1)\nRequirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (1.16.0)\nRequirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (1.16.0)\nRequirement already satisfied: packaging<25 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (24.2)\nRequirement already satisfied: protobuf<7,>=3.12.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (3.20.3)\nRequirement already satisfied: pydantic<3,>=1.10.8 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (2.11.3)\nRequirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (2.32.3)\nRequirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (0.5.3)\nRequirement already satisfied: typing-extensions<5,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (4.13.1)\nRequirement already satisfied: uvicorn<1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (0.34.2)\nRequirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic!=1.10.0,<2->mlflow) (1.3.9)\nRequirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from dagshub-annotation-converter>=0.1.5->dagshub) (5.3.1)\nRequirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from dagshub-annotation-converter>=0.1.5->dagshub) (11.1.0)\nRequirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from docker<8,>=4.0.0->mlflow) (2.3.0)\nRequirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (3.1.3)\nRequirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (2.2.0)\nRequirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (1.9.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from GitPython>=3.1.29->dagshub) (4.0.12)\nRequirement already satisfied: graphql-core<3.3,>=3.1 in /usr/local/lib/python3.11/dist-packages (from graphene<4->mlflow) (3.2.4)\nRequirement already satisfied: graphql-relay<3.3,>=3.1 in /usr/local/lib/python3.11/dist-packages (from graphene<4->mlflow) (3.2.0)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->dagshub) (3.7.1)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->dagshub) (2025.1.31)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->dagshub) (1.0.7)\nRequirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->dagshub) (3.10)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.23.0->dagshub) (0.14.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2<4,>=2.11->mlflow) (3.0.2)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (4.56.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (1.4.8)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (3.2.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3->mlflow) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3->mlflow) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3->mlflow) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3->mlflow) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3->mlflow) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3->mlflow) (2.4.1)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->dagshub) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->dagshub) (2025.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil->dagshub) (1.17.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.1.0->dagshub) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.1.0->dagshub) (2.19.1)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2->mlflow) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2->mlflow) (3.6.0)\nRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.1.1)\nRequirement already satisfied: botocore<1.38.0,>=1.37.29 in /usr/local/lib/python3.11/dist-packages (from boto3->dagshub) (1.37.29)\nRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from boto3->dagshub) (1.0.1)\nRequirement already satisfied: s3transfer<0.12.0,>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from boto3->dagshub) (0.11.4)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->dagshub) (3.26.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->dagshub) (0.9.0)\nRequirement already satisfied: yarl<2.0,>=1.6 in /usr/local/lib/python3.11/dist-packages (from gql[requests]->dagshub) (1.19.0)\nRequirement already satisfied: backoff<3.0,>=1.11.1 in /usr/local/lib/python3.11/dist-packages (from gql[requests]->dagshub) (2.2.1)\nRequirement already satisfied: requests-toolbelt<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from gql[requests]->dagshub) (1.0.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.23.0->dagshub) (1.3.1)\nRequirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.11/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow) (2.27.0)\nRequirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi<1->mlflow-skinny==2.22.0->mlflow) (0.46.2)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->GitPython>=3.1.29->dagshub) (5.0.2)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.22.0->mlflow) (3.21.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=13.1.0->dagshub) (0.1.2)\nRequirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.22.0->mlflow) (1.2.18)\nRequirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.22.0->mlflow) (75.1.0)\nRequirement already satisfied: opentelemetry-semantic-conventions==0.37b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.22.0->mlflow) (0.37b0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.22.0->mlflow) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.22.0->mlflow) (2.33.1)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.22.0->mlflow) (0.4.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.22.0->mlflow) (3.4.1)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->dagshub) (1.0.0)\nRequirement already satisfied: multidict>=4.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.6->gql[requests]->dagshub) (6.2.0)\nRequirement already satisfied: propcache>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.6->gql[requests]->dagshub) (0.3.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3->mlflow) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3->mlflow) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3->mlflow) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3->mlflow) (2024.2.0)\nRequirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.22.0->mlflow) (1.17.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow) (0.4.1)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow) (4.9)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3->mlflow) (2024.2.0)\nRequirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow) (0.6.1)\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"import dagshub\ndagshub.init(repo_owner='zeliz22', repo_name='ML_Fraud-Detection', mlflow=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T12:23:52.029432Z","iopub.execute_input":"2025-04-25T12:23:52.029747Z","iopub.status.idle":"2025-04-25T12:23:52.196170Z","shell.execute_reply.started":"2025-04-25T12:23:52.029719Z","shell.execute_reply":"2025-04-25T12:23:52.195439Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Initialized MLflow to track repo \u001b[32m\"zeliz22/ML_Fraud-Detection\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"zeliz22/ML_Fraud-Detection\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Repository zeliz22/ML_Fraud-Detection initialized!\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository zeliz22/ML_Fraud-Detection initialized!\n</pre>\n"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"train_transaction =  pd.read_csv('/kaggle/input/ieee-fraud-detection/train_transaction.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T12:23:52.197157Z","iopub.execute_input":"2025-04-25T12:23:52.197467Z","iopub.status.idle":"2025-04-25T12:24:16.518625Z","shell.execute_reply.started":"2025-04-25T12:23:52.197444Z","shell.execute_reply":"2025-04-25T12:24:16.517612Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ndef prepare_data(df, target='isFraud', test_size=0.15, random_state=42):\n    # Split train/val/test\n    train_val, test = train_test_split(\n        df, test_size=test_size, stratify=df[target], random_state=random_state\n    )\n    train, val = train_test_split(\n        train_val, \n        test_size=test_size/(1-test_size),  # Adjust for nested split\n        stratify=train_val[target],\n        random_state=random_state\n    )\n    \n    # Separate X/y\n    def _split(df):\n        return df.drop(columns=[target, 'TransactionID']), df[target]\n    \n    X_train, y_train = _split(train)\n    X_val, y_val = _split(val)\n    X_test, y_test = _split(test)\n    \n    return X_train, X_val, X_test, y_train, y_val, y_test\n\nX_train, X_val, X_test, y_train, y_val, y_test = prepare_data(train_transaction)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T12:24:16.521132Z","iopub.execute_input":"2025-04-25T12:24:16.521463Z","iopub.status.idle":"2025-04-25T12:24:22.034169Z","shell.execute_reply.started":"2025-04-25T12:24:16.521440Z","shell.execute_reply":"2025-04-25T12:24:22.033077Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"from sklearn.base import BaseEstimator, TransformerMixin\nimport pandas as pd\nimport numpy as np\nfrom typing import Dict, Optional, Union\n\nclass DataCleaner(BaseEstimator, TransformerMixin):\n    def __init__(self, \n                 numeric_strategy: str = 'mean',\n                 categorical_strategy: str = 'most_frequent',\n                 numeric_fill_value: Optional[Union[int, float]] = None,\n                 categorical_fill_value: Optional[str] = None,\n                 drop_threshold: float = 0.8):\n\n        self.numeric_strategy = numeric_strategy\n        self.categorical_strategy = categorical_strategy\n        self.numeric_fill_value = numeric_fill_value\n        self.categorical_fill_value = categorical_fill_value\n        self.drop_threshold = drop_threshold\n        self.numeric_impute_values_ = {}\n        self.categorical_impute_values_ = {}\n        self.columns_to_drop_ = []\n\n    def fit(self, X: pd.DataFrame, y=None):\n        \"\"\"Learn imputation values from the data\"\"\"\n        \n        # Identify columns to drop\n        null_ratios = X.isnull().mean()\n        self.columns_to_drop_ = list(null_ratios[null_ratios > self.drop_threshold].index)\n        X_clean = X.drop(columns=self.columns_to_drop_)\n        \n        # Separate numeric and categorical columns\n        numeric_cols = X_clean.select_dtypes(include=np.number).columns\n        categorical_cols = X_clean.select_dtypes(exclude=np.number).columns\n        \n        # Calculate numeric imputation values\n        for col in numeric_cols:\n            if self.numeric_strategy == 'mean':\n                self.numeric_impute_values_[col] = X_clean[col].mean()\n            elif self.numeric_strategy == 'median':\n                self.numeric_impute_values_[col] = X_clean[col].median()\n            elif self.numeric_strategy == 'constant':\n                if self.numeric_fill_value is None:\n                    raise ValueError(\"numeric_fill_value must be specified for constant strategy\")\n                self.numeric_impute_values_[col] = self.numeric_fill_value\n            elif self.numeric_strategy != 'drop':\n                raise ValueError(f\"Unknown numeric strategy: {self.numeric_strategy}\")\n        \n        # Calculate categorical imputation values\n        for col in categorical_cols:\n            if self.categorical_strategy == 'most_frequent':\n                self.categorical_impute_values_[col] = X_clean[col].mode()[0]\n            elif self.categorical_strategy == 'constant':\n                if self.categorical_fill_value is None:\n                    raise ValueError(\"categorical_fill_value must be specified for constant strategy\")\n                self.categorical_impute_values_[col] = self.categorical_fill_value\n            elif self.categorical_strategy != 'drop':\n                raise ValueError(f\"Unknown categorical strategy: {self.categorical_strategy}\")\n        \n        return self\n\n    def transform(self, X: pd.DataFrame) -> pd.DataFrame:\n        \"\"\"Apply the learned imputation to new data\"\"\"\n        \n        # Drop high-null columns\n        X_clean = X.drop(columns=self.columns_to_drop_)\n        \n        # Separate numeric and categorical columns\n        numeric_cols = X_clean.select_dtypes(include=np.number).columns\n        categorical_cols = X_clean.select_dtypes(exclude=np.number).columns\n        \n        # Apply numeric imputation\n        for col in numeric_cols:\n            if col in self.numeric_impute_values_:\n                X_clean[col] = X_clean[col].fillna(self.numeric_impute_values_[col])\n            elif self.numeric_strategy == 'drop':\n                X_clean = X_clean.dropna(subset=[col])\n        \n        # Apply categorical imputation\n        for col in categorical_cols:\n            if col in self.categorical_impute_values_:\n                X_clean[col] = X_clean[col].fillna(self.categorical_impute_values_[col])\n            elif self.categorical_strategy == 'drop':\n                X_clean = X_clean.dropna(subset=[col])\n        \n        return X_clean\n\n    def fit_transform(self, X: pd.DataFrame, y=None) -> pd.DataFrame:\n        \"\"\"Fit and transform in one step\"\"\"\n        return self.fit(X, y).transform(X)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T12:24:22.035267Z","iopub.execute_input":"2025-04-25T12:24:22.035605Z","iopub.status.idle":"2025-04-25T12:24:22.052358Z","shell.execute_reply.started":"2025-04-25T12:24:22.035583Z","shell.execute_reply":"2025-04-25T12:24:22.051365Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"import mlflow\nimport pandas as pd\nfrom sklearn.base import BaseEstimator, TransformerMixin\n\nclass AdvancedDataCleaner(BaseEstimator, TransformerMixin):\n    def __init__(self, missing_threshold=1):\n        self.missing_threshold = missing_threshold\n        self.numeric_fill = -999\n        self.categorical_fill = \"MISSING\"\n        self.columns_dropped = []\n        self.missing_stats = {}\n        \n    def fit(self, X, y=None):\n        # Calculate missing percentages\n        missing_percent = X.isnull().mean()\n        self.missing_stats = missing_percent.to_dict()\n        \n        # Identify columns to drop\n        self.columns_dropped = list(missing_percent[missing_percent > self.missing_threshold].index)\n        self.columns_kept = [col for col in X.columns if col not in self.columns_dropped]\n        \n        return self\n    \n    def transform(self, X):\n        X = X.copy()\n        \n        # 1. Drop high-missing columns\n        X = X.drop(columns=self.columns_dropped)\n        \n        # 2. Fill remaining missing values\n        num_cols = X.select_dtypes(include=['number']).columns\n        cat_cols = X.select_dtypes(exclude=['number']).columns\n        \n        X[num_cols] = X[num_cols].fillna(self.numeric_fill)\n        X[cat_cols] = X[cat_cols].fillna(self.categorical_fill)\n        \n        return X","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T12:24:22.053479Z","iopub.execute_input":"2025-04-25T12:24:22.053801Z","iopub.status.idle":"2025-04-25T12:24:22.084316Z","shell.execute_reply.started":"2025-04-25T12:24:22.053778Z","shell.execute_reply":"2025-04-25T12:24:22.083346Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n\nclass CustomEncoder:\n    def __init__(self, threshold = 3):\n        self.threshold = threshold\n        \n        # Initialize encoders\n        self.one_hot_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n        self.ordinal_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n        \n        # Store feature names for one-hot encoding\n        self.one_hot_feature_names = None\n        \n    def fit(self, X, y=None):\n\n        cat_cols = [col for col in X.columns if X[col].dtype == 'object']\n        s = X[cat_cols].nunique()\n\n        self.ordinal_cols = list(s[s > self.threshold].index)\n        self.one_hot_cols = list(s[s <= self.threshold].index)\n\n        if self.one_hot_cols:\n            self.one_hot_encoder.fit(X[self.one_hot_cols])\n            self.one_hot_feature_names = self.one_hot_encoder.get_feature_names_out(self.one_hot_cols)\n        \n        if self.ordinal_cols:\n            self.ordinal_encoder.fit(X[self.ordinal_cols])\n        \n        return self\n    \n    def transform(self, X):\n\n        X_transformed = X.copy()\n        \n        # Apply One-Hot Encoding\n        if self.one_hot_cols:\n            one_hot_encoded = self.one_hot_encoder.transform(X[self.one_hot_cols])\n            one_hot_df = pd.DataFrame(one_hot_encoded, columns=self.one_hot_feature_names, index=X.index)\n            X_transformed = pd.concat([X_transformed, one_hot_df], axis=1)\n            X_transformed.drop(self.one_hot_cols, axis=1, inplace=True)\n        \n        # Apply Ordinal Encoding\n        if self.ordinal_cols:\n            ordinal_encoded = self.ordinal_encoder.transform(X[self.ordinal_cols])\n            ordinal_df = pd.DataFrame(ordinal_encoded, columns=self.ordinal_cols, index=X.index)\n            X_transformed[self.ordinal_cols] = ordinal_df\n        \n        return X_transformed\n    \n    def fit_transform(self, X, y = None):\n        return self.fit(X).transform(X)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T12:24:22.085425Z","iopub.execute_input":"2025-04-25T12:24:22.085752Z","iopub.status.idle":"2025-04-25T12:24:22.109197Z","shell.execute_reply.started":"2025-04-25T12:24:22.085730Z","shell.execute_reply":"2025-04-25T12:24:22.108260Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.base import BaseEstimator, TransformerMixin\n\nclass CorrelationFeatureDropper(BaseEstimator, TransformerMixin):\n    def __init__(self, threshold=0.8):\n        self.threshold = threshold\n        self.features_to_drop = []\n        self.high_corr_pairs = []\n        \n    def fit(self, X, y): \n        X_corr = X.copy()\n        X_corr['isFraud'] = y\n        corr_matrix = X_corr.corr().abs()\n        \n        for i in range(len(corr_matrix.columns)):\n            for j in range(i+1, len(corr_matrix.columns)):\n                \n                if corr_matrix.iloc[i, j] > self.threshold:\n                    self.high_corr_pairs.append((corr_matrix.columns[i], corr_matrix.columns[j], corr_matrix.iloc[i, j]))\n                    \n        for feat1, feat2, _ in self.high_corr_pairs:\n            if abs(X[feat1].corr(y)) < abs(X[feat2].corr(y)):\n                self.features_to_drop.append(feat1)\n            else:\n                self.features_to_drop.append(feat2)\n        \n        self.features_to_drop = list(set(self.features_to_drop))\n        return self\n\n    \n    def transform(self, X):\n      return X.drop(columns=self.features_to_drop)\n        \n    def fit_transform(self, X, y):\n        return self.fit(X, y).transform(X)\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T12:24:22.110690Z","iopub.execute_input":"2025-04-25T12:24:22.111090Z","iopub.status.idle":"2025-04-25T12:24:22.135874Z","shell.execute_reply.started":"2025-04-25T12:24:22.111057Z","shell.execute_reply":"2025-04-25T12:24:22.134911Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"pip uninstall scikit-learn imbalanced-learn -y","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T12:24:22.137207Z","iopub.execute_input":"2025-04-25T12:24:22.137564Z","iopub.status.idle":"2025-04-25T12:24:23.978918Z","shell.execute_reply.started":"2025-04-25T12:24:22.137541Z","shell.execute_reply":"2025-04-25T12:24:23.977548Z"}},"outputs":[{"name":"stdout","text":"Found existing installation: scikit-learn 1.2.2\nUninstalling scikit-learn-1.2.2:\n  Successfully uninstalled scikit-learn-1.2.2\nFound existing installation: imbalanced-learn 0.10.1\nUninstalling imbalanced-learn-0.10.1:\n  Successfully uninstalled imbalanced-learn-0.10.1\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":36},{"cell_type":"code","source":"pip install scikit-learn==1.2.2 imbalanced-learn==0.10.1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T12:24:23.982166Z","iopub.execute_input":"2025-04-25T12:24:23.982637Z","iopub.status.idle":"2025-04-25T12:24:31.187942Z","shell.execute_reply.started":"2025-04-25T12:24:23.982591Z","shell.execute_reply":"2025-04-25T12:24:31.186696Z"}},"outputs":[{"name":"stdout","text":"Collecting scikit-learn==1.2.2\n  Using cached scikit_learn-1.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\nCollecting imbalanced-learn==0.10.1\n  Using cached imbalanced_learn-0.10.1-py3-none-any.whl.metadata (8.2 kB)\nRequirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2) (1.26.4)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2) (1.15.2)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2) (3.6.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn==1.2.2) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn==1.2.2) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn==1.2.2) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn==1.2.2) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn==1.2.2) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn==1.2.2) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn==1.2.2) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn==1.2.2) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17.3->scikit-learn==1.2.2) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17.3->scikit-learn==1.2.2) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17.3->scikit-learn==1.2.2) (2024.2.0)\nUsing cached scikit_learn-1.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\nUsing cached imbalanced_learn-0.10.1-py3-none-any.whl (226 kB)\nInstalling collected packages: scikit-learn, imbalanced-learn\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nnilearn 0.11.1 requires scikit-learn>=1.4.0, but you have scikit-learn 1.2.2 which is incompatible.\nbigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed imbalanced-learn-0.10.1 scikit-learn-1.2.2\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"from imblearn.pipeline import Pipeline as ImbPipeline\nfrom sklearn.linear_model import LogisticRegression\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.feature_selection import SelectFromModel\nfrom imblearn.under_sampling import RandomUnderSampler\n\n\npipeline = ImbPipeline([\n    ('cleaner', AdvancedDataCleaner()),\n    ('encoder', CustomEncoder()),\n    ('scaler', StandardScaler()),  # Important for logistic regression\n    # ('feature_selector', SelectFromModel(\n    #     LogisticRegression(class_weight='balanced', penalty='l1', solver='liblinear'),\n    #     threshold=\"median\")),\n    ('classifier', LogisticRegression(\n        class_weight='balanced',\n        max_iter=1000,\n        random_state=42,\n        penalty='l2',\n        C=0.1,\n        solver='lbfgs'))\n])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T12:24:31.189580Z","iopub.execute_input":"2025-04-25T12:24:31.189971Z","iopub.status.idle":"2025-04-25T12:24:31.198189Z","shell.execute_reply.started":"2025-04-25T12:24:31.189936Z","shell.execute_reply":"2025-04-25T12:24:31.196968Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"import mlflow\nfrom sklearn.metrics import roc_auc_score\n\n# Set up MLflow experiment\nmlflow.set_experiment(\"Basic_log_regression\")\n\n# Start a new run\nwith mlflow.start_run(run_name=\"saving all columns and its missing values + encoder\"):\n    # Log parameters\n    mlflow.log_params({\n        \"model_type\": \"LogisticRegression\",\n        \"missing_values\": \"-999 for numeric,'MISSING' for categorical\",\n        \"encoding\": \"WOE + one_hot_encoding(columns with unique<3)\",\n        \"scaler\": \"StandartScaler\"\n    })\n    \n    # Train and evaluate model\n    pipeline.fit(X_train, y_train)\n    train_preds = pipeline.predict_proba(X_train)[:, 1]\n    val_preds = pipeline.predict_proba(X_val)[:, 1]\n    roc_auc_train = roc_auc_score(y_train, train_preds)\n    roc_auc = roc_auc_score(y_val, val_preds)\n    \n    # Log metrics\n    mlflow.log_metric(\"val_roc_auc_val\", roc_auc)\n    mlflow.log_metric(\"val_roc_auc_train\", roc_auc_train)\n    print(f\"Logged ROC-AUC_VAL: {roc_auc:.4f}\")\n    print(f\"Logged ROC-AUC_TRAIN: {roc_auc_train:.4f}\")\n\n    \n    # Log the model\n    mlflow.sklearn.log_model(pipeline, \"model\")\n    \n    # Add a tag to identify this as baseline\n    mlflow.set_tag(\"stage\", \"baseline\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-25T12:24:31.199401Z","iopub.execute_input":"2025-04-25T12:24:31.199844Z","iopub.status.idle":"2025-04-25T12:28:30.949945Z","shell.execute_reply.started":"2025-04-25T12:24:31.199811Z","shell.execute_reply":"2025-04-25T12:28:30.948719Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"},{"name":"stdout","text":"Logged ROC-AUC_VAL: 0.8446\nLogged ROC-AUC_TRAIN: 0.8457\n","output_type":"stream"},{"name":"stderr","text":"\u001b[31m2025/04/25 12:28:28 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"🏃 View run saving all columns and its missing values + encoder at: https://dagshub.com/zeliz22/ML_Fraud-Detection.mlflow/#/experiments/0/runs/08b4eb47315b49dfa7ff74fa4daa8eed\n🧪 View experiment at: https://dagshub.com/zeliz22/ML_Fraud-Detection.mlflow/#/experiments/0\n","output_type":"stream"}],"execution_count":39}]}