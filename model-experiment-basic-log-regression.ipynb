{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cc889bc",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-04-24T21:46:58.272267Z",
     "iopub.status.busy": "2025-04-24T21:46:58.272025Z",
     "iopub.status.idle": "2025-04-24T21:47:09.157974Z",
     "shell.execute_reply": "2025-04-24T21:47:09.157151Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 10.891712,
     "end_time": "2025-04-24T21:47:09.159430",
     "exception": false,
     "start_time": "2025-04-24T21:46:58.267718",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dagshub\r\n",
      "  Downloading dagshub-0.5.9-py3-none-any.whl.metadata (12 kB)\r\n",
      "Collecting mlflow\r\n",
      "  Downloading mlflow-2.22.0-py3-none-any.whl.metadata (30 kB)\r\n",
      "Requirement already satisfied: PyYAML>=5 in /usr/local/lib/python3.11/dist-packages (from dagshub) (6.0.2)\r\n",
      "Collecting appdirs>=1.4.4 (from dagshub)\r\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\r\n",
      "Requirement already satisfied: click>=8.0.4 in /usr/local/lib/python3.11/dist-packages (from dagshub) (8.1.8)\r\n",
      "Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from dagshub) (0.28.1)\r\n",
      "Requirement already satisfied: GitPython>=3.1.29 in /usr/local/lib/python3.11/dist-packages (from dagshub) (3.1.44)\r\n",
      "Requirement already satisfied: rich>=13.1.0 in /usr/local/lib/python3.11/dist-packages (from dagshub) (14.0.0)\r\n",
      "Collecting dacite~=1.6.0 (from dagshub)\r\n",
      "  Downloading dacite-1.6.0-py3-none-any.whl.metadata (14 kB)\r\n",
      "Requirement already satisfied: tenacity>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from dagshub) (9.0.0)\r\n",
      "Collecting gql[requests] (from dagshub)\r\n",
      "  Downloading gql-3.5.2-py2.py3-none-any.whl.metadata (9.4 kB)\r\n",
      "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from dagshub) (0.6.7)\r\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from dagshub) (2.2.3)\r\n",
      "Collecting treelib>=1.6.4 (from dagshub)\r\n",
      "  Downloading treelib-1.7.1-py3-none-any.whl.metadata (1.4 kB)\r\n",
      "Collecting pathvalidate>=3.0.0 (from dagshub)\r\n",
      "  Downloading pathvalidate-3.2.3-py3-none-any.whl.metadata (12 kB)\r\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from dagshub) (2.9.0.post0)\r\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.11/dist-packages (from dagshub) (1.37.29)\r\n",
      "Requirement already satisfied: semver in /usr/local/lib/python3.11/dist-packages (from dagshub) (3.0.4)\r\n",
      "Collecting dagshub-annotation-converter>=0.1.5 (from dagshub)\r\n",
      "  Downloading dagshub_annotation_converter-0.1.9-py3-none-any.whl.metadata (2.5 kB)\r\n",
      "Collecting mlflow-skinny==2.22.0 (from mlflow)\r\n",
      "  Downloading mlflow_skinny-2.22.0-py3-none-any.whl.metadata (31 kB)\r\n",
      "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.1.0)\r\n",
      "Requirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.1.6)\r\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.15.2)\r\n",
      "Requirement already satisfied: docker<8,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (7.1.0)\r\n",
      "Collecting graphene<4 (from mlflow)\r\n",
      "  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\r\n",
      "Collecting gunicorn<24 (from mlflow)\r\n",
      "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\r\n",
      "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.7)\r\n",
      "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.11/dist-packages (from mlflow) (3.7.5)\r\n",
      "Requirement already satisfied: numpy<3 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.26.4)\r\n",
      "Requirement already satisfied: pyarrow<20,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (19.0.1)\r\n",
      "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.2.2)\r\n",
      "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.11/dist-packages (from mlflow) (1.15.2)\r\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow) (2.0.38)\r\n",
      "Requirement already satisfied: cachetools<6,>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (5.5.2)\r\n",
      "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (3.1.1)\r\n",
      "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==2.22.0->mlflow)\r\n",
      "  Downloading databricks_sdk-0.50.0-py3-none-any.whl.metadata (38 kB)\r\n",
      "Collecting fastapi<1 (from mlflow-skinny==2.22.0->mlflow)\r\n",
      "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\r\n",
      "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (8.6.1)\r\n",
      "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (1.16.0)\r\n",
      "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (1.16.0)\r\n",
      "Requirement already satisfied: packaging<25 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (24.2)\r\n",
      "Requirement already satisfied: protobuf<7,>=3.12.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (3.20.3)\r\n",
      "Requirement already satisfied: pydantic<3,>=1.10.8 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (2.11.3)\r\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (2.32.3)\r\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (0.5.3)\r\n",
      "Requirement already satisfied: typing-extensions<5,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow) (4.13.1)\r\n",
      "Collecting uvicorn<1 (from mlflow-skinny==2.22.0->mlflow)\r\n",
      "  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\r\n",
      "Requirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic!=1.10.0,<2->mlflow) (1.3.9)\r\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from dagshub-annotation-converter>=0.1.5->dagshub) (5.3.1)\r\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from dagshub-annotation-converter>=0.1.5->dagshub) (11.1.0)\r\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from docker<8,>=4.0.0->mlflow) (2.3.0)\r\n",
      "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (3.1.3)\r\n",
      "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (2.2.0)\r\n",
      "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow) (1.9.0)\r\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from GitPython>=3.1.29->dagshub) (4.0.12)\r\n",
      "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\r\n",
      "  Downloading graphql_core-3.2.6-py3-none-any.whl.metadata (11 kB)\r\n",
      "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\r\n",
      "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\r\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->dagshub) (3.7.1)\r\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->dagshub) (2025.1.31)\r\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->dagshub) (1.0.7)\r\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->dagshub) (3.10)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.23.0->dagshub) (0.14.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2<4,>=2.11->mlflow) (3.0.2)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (1.3.1)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (4.56.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (1.4.8)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4->mlflow) (3.2.1)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3->mlflow) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3->mlflow) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3->mlflow) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3->mlflow) (2025.1.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3->mlflow) (2022.1.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3->mlflow) (2.4.1)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->dagshub) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->dagshub) (2025.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil->dagshub) (1.17.0)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.1.0->dagshub) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.1.0->dagshub) (2.19.1)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2->mlflow) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2->mlflow) (3.6.0)\r\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.1.1)\r\n",
      "Requirement already satisfied: botocore<1.38.0,>=1.37.29 in /usr/local/lib/python3.11/dist-packages (from boto3->dagshub) (1.37.29)\r\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from boto3->dagshub) (1.0.1)\r\n",
      "Requirement already satisfied: s3transfer<0.12.0,>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from boto3->dagshub) (0.11.4)\r\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->dagshub) (3.26.1)\r\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->dagshub) (0.9.0)\r\n",
      "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\r\n",
      "  Downloading graphql_core-3.2.4-py3-none-any.whl.metadata (10 kB)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.6 in /usr/local/lib/python3.11/dist-packages (from gql[requests]->dagshub) (1.19.0)\r\n",
      "Collecting backoff<3.0,>=1.11.1 (from gql[requests]->dagshub)\r\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\r\n",
      "Requirement already satisfied: requests-toolbelt<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from gql[requests]->dagshub) (1.0.0)\r\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.23.0->dagshub) (1.3.1)\r\n",
      "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.11/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow) (2.27.0)\r\n",
      "Collecting starlette<0.47.0,>=0.40.0 (from fastapi<1->mlflow-skinny==2.22.0->mlflow)\r\n",
      "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\r\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->GitPython>=3.1.29->dagshub) (5.0.2)\r\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.22.0->mlflow) (3.21.0)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=13.1.0->dagshub) (0.1.2)\r\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.22.0->mlflow) (1.2.18)\r\n",
      "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.22.0->mlflow) (75.1.0)\r\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.37b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.22.0->mlflow) (0.37b0)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.22.0->mlflow) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.22.0->mlflow) (2.33.1)\r\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.22.0->mlflow) (0.4.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==2.22.0->mlflow) (3.4.1)\r\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->dagshub) (1.0.0)\r\n",
      "Requirement already satisfied: multidict>=4.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.6->gql[requests]->dagshub) (6.2.0)\r\n",
      "Requirement already satisfied: propcache>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.6->gql[requests]->dagshub) (0.3.1)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3->mlflow) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3->mlflow) (2022.1.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3->mlflow) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3->mlflow) (2024.2.0)\r\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.22.0->mlflow) (1.17.2)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow) (0.4.1)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow) (4.9)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3->mlflow) (2024.2.0)\r\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow) (0.6.1)\r\n",
      "Downloading dagshub-0.5.9-py3-none-any.whl (260 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m260.1/260.1 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading mlflow-2.22.0-py3-none-any.whl (29.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.0/29.0 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading mlflow_skinny-2.22.0-py3-none-any.whl (6.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\r\n",
      "Downloading dacite-1.6.0-py3-none-any.whl (12 kB)\r\n",
      "Downloading dagshub_annotation_converter-0.1.9-py3-none-any.whl (33 kB)\r\n",
      "Downloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pathvalidate-3.2.3-py3-none-any.whl (24 kB)\r\n",
      "Downloading treelib-1.7.1-py3-none-any.whl (19 kB)\r\n",
      "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\r\n",
      "Downloading databricks_sdk-0.50.0-py3-none-any.whl (692 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m692.3/692.3 kB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading fastapi-0.115.12-py3-none-any.whl (95 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading graphql_core-3.2.4-py3-none-any.whl (203 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.2/203.2 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\r\n",
      "Downloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading gql-3.5.2-py2.py3-none-any.whl (74 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.3/74.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading starlette-0.46.2-py3-none-any.whl (72 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: appdirs, uvicorn, treelib, pathvalidate, gunicorn, graphql-core, dacite, backoff, starlette, graphql-relay, gql, graphene, fastapi, databricks-sdk, mlflow-skinny, dagshub-annotation-converter, mlflow, dagshub\r\n",
      "  Attempting uninstall: dacite\r\n",
      "    Found existing installation: dacite 1.9.2\r\n",
      "    Uninstalling dacite-1.9.2:\r\n",
      "      Successfully uninstalled dacite-1.9.2\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "ydata-profiling 4.16.1 requires dacite>=1.8, but you have dacite 1.6.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed appdirs-1.4.4 backoff-2.2.1 dacite-1.6.0 dagshub-0.5.9 dagshub-annotation-converter-0.1.9 databricks-sdk-0.50.0 fastapi-0.115.12 gql-3.5.2 graphene-3.4.3 graphql-core-3.2.4 graphql-relay-3.2.0 gunicorn-23.0.0 mlflow-2.22.0 mlflow-skinny-2.22.0 pathvalidate-3.2.3 starlette-0.46.2 treelib-1.7.1 uvicorn-0.34.2\r\n"
     ]
    }
   ],
   "source": [
    "!pip install dagshub mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffdf5535",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-24T21:47:09.169541Z",
     "iopub.status.busy": "2025-04-24T21:47:09.169286Z",
     "iopub.status.idle": "2025-04-24T21:47:10.423434Z",
     "shell.execute_reply": "2025-04-24T21:47:10.422361Z"
    },
    "papermill": {
     "duration": 1.260378,
     "end_time": "2025-04-24T21:47:10.424738",
     "exception": false,
     "start_time": "2025-04-24T21:47:09.164360",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/ieee-fraud-detection/sample_submission.csv\n",
      "/kaggle/input/ieee-fraud-detection/test_identity.csv\n",
      "/kaggle/input/ieee-fraud-detection/train_identity.csv\n",
      "/kaggle/input/ieee-fraud-detection/test_transaction.csv\n",
      "/kaggle/input/ieee-fraud-detection/train_transaction.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2407ca4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T21:47:10.434462Z",
     "iopub.status.busy": "2025-04-24T21:47:10.434048Z",
     "iopub.status.idle": "2025-04-24T21:47:42.068733Z",
     "shell.execute_reply": "2025-04-24T21:47:42.068028Z"
    },
    "papermill": {
     "duration": 31.640645,
     "end_time": "2025-04-24T21:47:42.069882",
     "exception": false,
     "start_time": "2025-04-24T21:47:10.429237",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                                       <span style=\"font-weight: bold\">❗❗❗ AUTHORIZATION REQUIRED ❗❗❗</span>                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "                                       \u001b[1m❗❗❗ AUTHORIZATION REQUIRED ❗❗❗\u001b[0m                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc60a109397142128d4ba1d1b6316885",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Open the following link in your browser to authorize the client:\n",
      "https://dagshub.com/login/oauth/authorize?state=72c228da-a9e6-4f23-9874-08e1f03054fe&client_id=32b60ba385aa7cecf24046d8195a71c07dd345d9657977863b52e7748e0f0f28&middleman_request_id=8e017d20b13705ffdd59eac829b816f0b52528672242d1e61aed36c89dd79433\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as zeliz22\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as zeliz22\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"zeliz22/ML_House-Pricing\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"zeliz22/ML_House-Pricing\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository zeliz22/ML_House-Pricing initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository zeliz22/ML_House-Pricing initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dagshub\n",
    "dagshub.init(repo_owner='zeliz22', repo_name='ML_House-Pricing', mlflow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fb19e26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T21:47:42.718322Z",
     "iopub.status.busy": "2025-04-24T21:47:42.718124Z",
     "iopub.status.idle": "2025-04-24T21:48:05.391284Z",
     "shell.execute_reply": "2025-04-24T21:48:05.390195Z"
    },
    "papermill": {
     "duration": 23.314693,
     "end_time": "2025-04-24T21:48:05.392590",
     "exception": false,
     "start_time": "2025-04-24T21:47:42.077897",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_transaction =  pd.read_csv('/kaggle/input/ieee-fraud-detection/train_transaction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8317708",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T21:48:05.403192Z",
     "iopub.status.busy": "2025-04-24T21:48:05.402963Z",
     "iopub.status.idle": "2025-04-24T21:48:09.986254Z",
     "shell.execute_reply": "2025-04-24T21:48:09.985235Z"
    },
    "papermill": {
     "duration": 4.590029,
     "end_time": "2025-04-24T21:48:09.987643",
     "exception": false,
     "start_time": "2025-04-24T21:48:05.397614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def prepare_data(df, target='isFraud', test_size=0.15, random_state=42):\n",
    "    # Split train/val/test\n",
    "    train_val, test = train_test_split(\n",
    "        df, test_size=test_size, stratify=df[target], random_state=random_state\n",
    "    )\n",
    "    train, val = train_test_split(\n",
    "        train_val, \n",
    "        test_size=test_size/(1-test_size),  # Adjust for nested split\n",
    "        stratify=train_val[target],\n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    # Separate X/y\n",
    "    def _split(df):\n",
    "        return df.drop(columns=[target, 'TransactionID']), df[target]\n",
    "    \n",
    "    X_train, y_train = _split(train)\n",
    "    X_val, y_val = _split(val)\n",
    "    X_test, y_test = _split(test)\n",
    "    \n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = prepare_data(train_transaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0ebc39e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T21:48:10.000525Z",
     "iopub.status.busy": "2025-04-24T21:48:10.000065Z",
     "iopub.status.idle": "2025-04-24T21:48:10.012587Z",
     "shell.execute_reply": "2025-04-24T21:48:10.011960Z"
    },
    "papermill": {
     "duration": 0.019719,
     "end_time": "2025-04-24T21:48:10.013611",
     "exception": false,
     "start_time": "2025-04-24T21:48:09.993892",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, Optional, Union\n",
    "\n",
    "class DataCleaner(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, \n",
    "                 numeric_strategy: str = 'mean',\n",
    "                 categorical_strategy: str = 'most_frequent',\n",
    "                 numeric_fill_value: Optional[Union[int, float]] = None,\n",
    "                 categorical_fill_value: Optional[str] = None,\n",
    "                 drop_threshold: float = 0.8):\n",
    "\n",
    "        self.numeric_strategy = numeric_strategy\n",
    "        self.categorical_strategy = categorical_strategy\n",
    "        self.numeric_fill_value = numeric_fill_value\n",
    "        self.categorical_fill_value = categorical_fill_value\n",
    "        self.drop_threshold = drop_threshold\n",
    "        self.numeric_impute_values_ = {}\n",
    "        self.categorical_impute_values_ = {}\n",
    "        self.columns_to_drop_ = []\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y=None):\n",
    "        \"\"\"Learn imputation values from the data\"\"\"\n",
    "        \n",
    "        # Identify columns to drop\n",
    "        null_ratios = X.isnull().mean()\n",
    "        self.columns_to_drop_ = list(null_ratios[null_ratios > self.drop_threshold].index)\n",
    "        X_clean = X.drop(columns=self.columns_to_drop_)\n",
    "        \n",
    "        # Separate numeric and categorical columns\n",
    "        numeric_cols = X_clean.select_dtypes(include=np.number).columns\n",
    "        categorical_cols = X_clean.select_dtypes(exclude=np.number).columns\n",
    "        \n",
    "        # Calculate numeric imputation values\n",
    "        for col in numeric_cols:\n",
    "            if self.numeric_strategy == 'mean':\n",
    "                self.numeric_impute_values_[col] = X_clean[col].mean()\n",
    "            elif self.numeric_strategy == 'median':\n",
    "                self.numeric_impute_values_[col] = X_clean[col].median()\n",
    "            elif self.numeric_strategy == 'constant':\n",
    "                if self.numeric_fill_value is None:\n",
    "                    raise ValueError(\"numeric_fill_value must be specified for constant strategy\")\n",
    "                self.numeric_impute_values_[col] = self.numeric_fill_value\n",
    "            elif self.numeric_strategy != 'drop':\n",
    "                raise ValueError(f\"Unknown numeric strategy: {self.numeric_strategy}\")\n",
    "        \n",
    "        # Calculate categorical imputation values\n",
    "        for col in categorical_cols:\n",
    "            if self.categorical_strategy == 'most_frequent':\n",
    "                self.categorical_impute_values_[col] = X_clean[col].mode()[0]\n",
    "            elif self.categorical_strategy == 'constant':\n",
    "                if self.categorical_fill_value is None:\n",
    "                    raise ValueError(\"categorical_fill_value must be specified for constant strategy\")\n",
    "                self.categorical_impute_values_[col] = self.categorical_fill_value\n",
    "            elif self.categorical_strategy != 'drop':\n",
    "                raise ValueError(f\"Unknown categorical strategy: {self.categorical_strategy}\")\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def transform(self, X: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Apply the learned imputation to new data\"\"\"\n",
    "        \n",
    "        # Drop high-null columns\n",
    "        X_clean = X.drop(columns=self.columns_to_drop_)\n",
    "        \n",
    "        # Separate numeric and categorical columns\n",
    "        numeric_cols = X_clean.select_dtypes(include=np.number).columns\n",
    "        categorical_cols = X_clean.select_dtypes(exclude=np.number).columns\n",
    "        \n",
    "        # Apply numeric imputation\n",
    "        for col in numeric_cols:\n",
    "            if col in self.numeric_impute_values_:\n",
    "                X_clean[col] = X_clean[col].fillna(self.numeric_impute_values_[col])\n",
    "            elif self.numeric_strategy == 'drop':\n",
    "                X_clean = X_clean.dropna(subset=[col])\n",
    "        \n",
    "        # Apply categorical imputation\n",
    "        for col in categorical_cols:\n",
    "            if col in self.categorical_impute_values_:\n",
    "                X_clean[col] = X_clean[col].fillna(self.categorical_impute_values_[col])\n",
    "            elif self.categorical_strategy == 'drop':\n",
    "                X_clean = X_clean.dropna(subset=[col])\n",
    "        \n",
    "        return X_clean\n",
    "\n",
    "    def fit_transform(self, X: pd.DataFrame, y=None) -> pd.DataFrame:\n",
    "        \"\"\"Fit and transform in one step\"\"\"\n",
    "        return self.fit(X, y).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c201c7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T21:48:10.024109Z",
     "iopub.status.busy": "2025-04-24T21:48:10.023904Z",
     "iopub.status.idle": "2025-04-24T21:48:10.030626Z",
     "shell.execute_reply": "2025-04-24T21:48:10.029982Z"
    },
    "papermill": {
     "duration": 0.0129,
     "end_time": "2025-04-24T21:48:10.031581",
     "exception": false,
     "start_time": "2025-04-24T21:48:10.018681",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "\n",
    "class CustomEncoder:\n",
    "    def __init__(self, threshold = 3):\n",
    "        self.threshold = threshold\n",
    "        \n",
    "        # Initialize encoders\n",
    "        self.one_hot_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "        self.ordinal_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "        \n",
    "        # Store feature names for one-hot encoding\n",
    "        self.one_hot_feature_names = None\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "\n",
    "        cat_cols = [col for col in X.columns if X[col].dtype == 'object']\n",
    "        s = X[cat_cols].nunique()\n",
    "\n",
    "        self.ordinal_cols = list(s[s > self.threshold].index)\n",
    "        self.one_hot_cols = list(s[s <= self.threshold].index)\n",
    "\n",
    "        if self.one_hot_cols:\n",
    "            self.one_hot_encoder.fit(X[self.one_hot_cols])\n",
    "            self.one_hot_feature_names = self.one_hot_encoder.get_feature_names_out(self.one_hot_cols)\n",
    "        \n",
    "        if self.ordinal_cols:\n",
    "            self.ordinal_encoder.fit(X[self.ordinal_cols])\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "\n",
    "        X_transformed = X.copy()\n",
    "        \n",
    "        # Apply One-Hot Encoding\n",
    "        if self.one_hot_cols:\n",
    "            one_hot_encoded = self.one_hot_encoder.transform(X[self.one_hot_cols])\n",
    "            one_hot_df = pd.DataFrame(one_hot_encoded, columns=self.one_hot_feature_names, index=X.index)\n",
    "            X_transformed = pd.concat([X_transformed, one_hot_df], axis=1)\n",
    "            X_transformed.drop(self.one_hot_cols, axis=1, inplace=True)\n",
    "        \n",
    "        # Apply Ordinal Encoding\n",
    "        if self.ordinal_cols:\n",
    "            ordinal_encoded = self.ordinal_encoder.transform(X[self.ordinal_cols])\n",
    "            ordinal_df = pd.DataFrame(ordinal_encoded, columns=self.ordinal_cols, index=X.index)\n",
    "            X_transformed[self.ordinal_cols] = ordinal_df\n",
    "        \n",
    "        return X_transformed\n",
    "    \n",
    "    def fit_transform(self, X, y = None):\n",
    "        return self.fit(X).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ed65022",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T21:48:10.041510Z",
     "iopub.status.busy": "2025-04-24T21:48:10.041275Z",
     "iopub.status.idle": "2025-04-24T21:48:10.047501Z",
     "shell.execute_reply": "2025-04-24T21:48:10.046864Z"
    },
    "papermill": {
     "duration": 0.012432,
     "end_time": "2025-04-24T21:48:10.048508",
     "exception": false,
     "start_time": "2025-04-24T21:48:10.036076",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class CorrelationFeatureDropper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, threshold=0.8):\n",
    "        self.threshold = threshold\n",
    "        self.features_to_drop = []\n",
    "        self.high_corr_pairs = []\n",
    "        \n",
    "    def fit(self, X, y): \n",
    "        X_corr = X.copy()\n",
    "        X_corr['isFraud'] = y\n",
    "        corr_matrix = X_corr.corr().abs()\n",
    "        \n",
    "        for i in range(len(corr_matrix.columns)):\n",
    "            for j in range(i+1, len(corr_matrix.columns)):\n",
    "                \n",
    "                if corr_matrix.iloc[i, j] > self.threshold:\n",
    "                    self.high_corr_pairs.append((corr_matrix.columns[i], corr_matrix.columns[j], corr_matrix.iloc[i, j]))\n",
    "                    \n",
    "        for feat1, feat2, _ in self.high_corr_pairs:\n",
    "            if abs(X[feat1].corr(y)) < abs(X[feat2].corr(y)):\n",
    "                self.features_to_drop.append(feat1)\n",
    "            else:\n",
    "                self.features_to_drop.append(feat2)\n",
    "        \n",
    "        self.features_to_drop = list(set(self.features_to_drop))\n",
    "        return self\n",
    "\n",
    "    \n",
    "    def transform(self, X):\n",
    "      return X.drop(columns=self.features_to_drop)\n",
    "        \n",
    "    def fit_transform(self, X, y):\n",
    "        return self.fit(X, y).transform(X)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6a8e47d",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-04-24T21:48:10.058782Z",
     "iopub.status.busy": "2025-04-24T21:48:10.058487Z",
     "iopub.status.idle": "2025-04-24T21:48:12.496726Z",
     "shell.execute_reply": "2025-04-24T21:48:12.494308Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 2.446548,
     "end_time": "2025-04-24T21:48:12.499674",
     "exception": false,
     "start_time": "2025-04-24T21:48:10.053126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: scikit-learn 1.2.2\r\n",
      "Uninstalling scikit-learn-1.2.2:\r\n",
      "  Successfully uninstalled scikit-learn-1.2.2\r\n",
      "Found existing installation: imbalanced-learn 0.13.0\r\n",
      "Uninstalling imbalanced-learn-0.13.0:\r\n",
      "  Successfully uninstalled imbalanced-learn-0.13.0\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip uninstall scikit-learn imbalanced-learn -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25b8ff2a",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-04-24T21:48:12.526597Z",
     "iopub.status.busy": "2025-04-24T21:48:12.526204Z",
     "iopub.status.idle": "2025-04-24T21:48:19.482761Z",
     "shell.execute_reply": "2025-04-24T21:48:19.481109Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 6.972289,
     "end_time": "2025-04-24T21:48:19.484690",
     "exception": false,
     "start_time": "2025-04-24T21:48:12.512401",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn==1.2.2\r\n",
      "  Downloading scikit_learn-1.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\r\n",
      "Collecting imbalanced-learn==0.10.1\r\n",
      "  Downloading imbalanced_learn-0.10.1-py3-none-any.whl.metadata (8.2 kB)\r\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2) (1.26.4)\r\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2) (1.15.2)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.2.2) (3.6.0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn==1.2.2) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn==1.2.2) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn==1.2.2) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn==1.2.2) (2025.1.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn==1.2.2) (2022.1.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17.3->scikit-learn==1.2.2) (2.4.1)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn==1.2.2) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17.3->scikit-learn==1.2.2) (2022.1.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17.3->scikit-learn==1.2.2) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17.3->scikit-learn==1.2.2) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17.3->scikit-learn==1.2.2) (2024.2.0)\r\n",
      "Downloading scikit_learn-1.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading imbalanced_learn-0.10.1-py3-none-any.whl (226 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.0/226.0 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: scikit-learn, imbalanced-learn\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "nilearn 0.11.1 requires scikit-learn>=1.4.0, but you have scikit-learn 1.2.2 which is incompatible.\r\n",
      "bigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\r\n",
      "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed imbalanced-learn-0.10.1 scikit-learn-1.2.2\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn==1.2.2 imbalanced-learn==0.10.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96e21063",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T21:48:19.499440Z",
     "iopub.status.busy": "2025-04-24T21:48:19.499157Z",
     "iopub.status.idle": "2025-04-24T21:48:19.590899Z",
     "shell.execute_reply": "2025-04-24T21:48:19.590100Z"
    },
    "papermill": {
     "duration": 0.100531,
     "end_time": "2025-04-24T21:48:19.592752",
     "exception": false,
     "start_time": "2025-04-24T21:48:19.492221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Assuming you've already defined your custom classes\n",
    "pipeline = ImbPipeline([\n",
    "    ('cleaner', DataCleaner()),\n",
    "    ('encoder', CustomEncoder()),\n",
    "    ('correlation_dropper', CorrelationFeatureDropper()),\n",
    "    ('smote', SMOTE(random_state=42)),  # Handling imbalance\n",
    "    ('classifier', LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7fa88829",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T21:48:19.611213Z",
     "iopub.status.busy": "2025-04-24T21:48:19.610979Z",
     "iopub.status.idle": "2025-04-24T21:51:06.871826Z",
     "shell.execute_reply": "2025-04-24T21:51:06.870850Z"
    },
    "papermill": {
     "duration": 167.271731,
     "end_time": "2025-04-24T21:51:06.873371",
     "exception": false,
     "start_time": "2025-04-24T21:48:19.601640",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored on calling ctypes callback function: <function ThreadpoolController._find_libraries_with_dl_iterate_phdr.<locals>.match_library_callback at 0x7eb95c148860>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/threadpoolctl.py\", line 1005, in match_library_callback\n",
      "    self._make_controller_from_path(filepath)\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/threadpoolctl.py\", line 1187, in _make_controller_from_path\n",
      "    lib_controller = controller_class(\n",
      "                     ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/threadpoolctl.py\", line 114, in __init__\n",
      "    self.dynlib = ctypes.CDLL(filepath, mode=_RTLD_NOLOAD)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/ctypes/__init__.py\", line 376, in __init__\n",
      "    self._handle = _dlopen(self._name, mode)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "OSError: dlopen() error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged ROC-AUC: 0.7453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/04/24 21:51:01 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run initial_run at: https://dagshub.com/zeliz22/ML_House-Pricing.mlflow/#/experiments/7/runs/2e6de227901a4ae0ae548913a1edbf83\n",
      "🧪 View experiment at: https://dagshub.com/zeliz22/ML_House-Pricing.mlflow/#/experiments/7\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Set up MLflow experiment\n",
    "mlflow.set_experiment(\"Basic_log_regression\")\n",
    "\n",
    "# Start a new run\n",
    "with mlflow.start_run(run_name=\"initial_run\"):\n",
    "    # Log parameters\n",
    "    mlflow.log_params({\n",
    "        \"model_type\": \"LogisticRegression\",\n",
    "        \"imbalance_handling\": \"SMOTE + class_weight='balanced'\",\n",
    "        \"missing_values\": \"mean for numeric, most_frequent for categorical\",\n",
    "        \"encoding\": \"WOE + one_hot_encoding(columns with unique<3)\",\n",
    "        \"feature_selection\": \"CorrelationFeatureDropper\"\n",
    "    })\n",
    "    \n",
    "    # Train and evaluate model\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    val_preds = pipeline.predict_proba(X_val)[:, 1]\n",
    "    roc_auc = roc_auc_score(y_val, val_preds)\n",
    "    \n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"val_roc_auc\", roc_auc)\n",
    "    print(f\"Logged ROC-AUC: {roc_auc:.4f}\")\n",
    "    \n",
    "    # Log the model\n",
    "    mlflow.sklearn.log_model(pipeline, \"model\")\n",
    "    \n",
    "    # Add a tag to identify this as baseline\n",
    "    mlflow.set_tag(\"stage\", \"baseline\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 568274,
     "sourceId": 14242,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 253.630474,
   "end_time": "2025-04-24T21:51:08.403503",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-24T21:46:54.773029",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "31b339fc49e647b1933f83cd306f8312": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fc60a109397142128d4ba1d1b6316885": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/output",
       "_model_module_version": "1.0.0",
       "_model_name": "OutputModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/output",
       "_view_module_version": "1.0.0",
       "_view_name": "OutputView",
       "layout": "IPY_MODEL_31b339fc49e647b1933f83cd306f8312",
       "msg_id": "",
       "outputs": [
        {
         "data": {
          "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">⠼</span> Waiting for authorization\n</pre>\n",
          "text/plain": "\u001b[32m⠼\u001b[0m Waiting for authorization\n"
         },
         "metadata": {},
         "output_type": "display_data"
        }
       ],
       "tabbable": null,
       "tooltip": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
