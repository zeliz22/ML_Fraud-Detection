#model_experiment_Basic_Log_regression
დასაწყისისთვის, გავტესტე მარტივი ლოჯისტიკური რეგრესია მხოლოდ train_transactionის საშუალებით, სანამ საქმეში aidentityს ჩავრთავდი. 
პირველი რანი "initial run": მისინგები შევავსე მოდით/მედიანით(დაიდროპა სვეტები, სადაც მისინგები>90%), გამოვიყენე WOE ენქოუდინგი(one_hot იმ სვეტებისთვის, სადაც იუნიქი<3). ასევე გავაკეთე კორელაციის დადროპვა. ვალიდაციაზე roc-auc მივიღე 0.74. 
მეორე რანი "saving_missing_values": შევცვალე მისინგების შევსება: ვივარაუდე, რომ შესაძლოა, მისინგნესი კორელაციაში იყოს დაფრედიქთებასთან, ამიტომ მისინგების პირდაპირ მოდით/მედიანით ჩანაცვლების მაგივრად, ჩავწერე მნიშვნელობები: -999/"MISSING"(დაიდროპა ქოლუმები, სადაც მისინგი >80%). ამან შედეგი უმიშვნელოდ გააუმჯობესა, მხოლოდ 0.1-ით და ავიდე 0.75ზე. 
მესამე რანი "saving all columns and its missing values": რადგან ვნახე, რომ მისინგ ველიუების "შენახვამ" დასწავლისას უკეთესი შედეგი გამოიღო, ვივარაუდე, რომ ის ქოლუმები, რომლებსაც ბევრი მისინგ ველიუ ჰქონდათ და ამის გამო ვშლიდი, შესაძლოა, პირიქით, დაგვხმარებოდა დასწავლის პროცესში, ამიტომ თრეშჰოლდი ავწიე 1ზე. ასევე, ფაიფლაინიდან ამოვიღე კორელაციის ფილტრი, რომ ყველა ქოლუმი შემენარჩუნებინა. ამან მომცა უკეთესი შედეგი: 0.79.



#missing values:
ჯერ შევამოწმე ეს ნალ ველიუები უფრო ხშირად ხომ არ გვხვდებოდა fraud შემთხვევებში, ვიდრე non_fraudში, ან პირიქით. რადგან მაინც იყო კორელაცია, პირდაპირ ნალების ჩანაცვლებას მოდით ან მედიანით, ვარჩიე რამდენიმე კატეგორად დაყოფა: პირდაპირ დავდროპე სვეტები, სადაც იყო >90%ზე. იმ ქოლუმენბისთვის, სადაც მისინგები იყო 50-90%, ვარჩიე flagების შექმნა, რადგან მაინც მაღალი რიცხვი გამოდიოდა და შესაძლოა რაიმე ფორმით ეგეც დაკავშირებული ყოფილიყო fraudის predictivityსთან. იქ სადაც დაბალი რიცხობრივად ნაკლები გამოდიოდა ნალები და ნაკლებ სავარაუდო იყო, მოეხდინა გავლენა ფრედიქთზე, სტანდარტულად შევცვალე moda/medianებით.
