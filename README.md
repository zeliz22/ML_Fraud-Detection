#model_experiment_Basic_Log_regression
დასაწყისისთვის, გავტესტე მარტივი ლოჯისტიკური რეგრესია მხოლოდ train_transactionის საშუალებით, სანამ საქმეში aidentityს ჩავრთავდი. 
*პირველი რანი "initial run"*: მისინგები შევავსე მოდით/მედიანით(დაიდროპა სვეტები, სადაც მისინგები>90%), გამოვიყენე WOE ენქოუდინგი(one_hot იმ სვეტებისთვის, სადაც იუნიქი<3). ასევე გავაკეთე კორელაციის დადროპვა. ვალიდაციაზე roc-auc მივიღე 0.74. 
*მეორე რანი "saving_missing_values"*: შევცვალე მისინგების შევსება: ვივარაუდე, რომ შესაძლოა, მისინგნესი კორელაციაში იყოს დაფრედიქთებასთან, ამიტომ მისინგების პირდაპირ მოდით/მედიანით ჩანაცვლების მაგივრად, ჩავწერე მნიშვნელობები: -999/"MISSING"(დაიდროპა ქოლუმები, სადაც მისინგი >80%). ამან შედეგი უმიშვნელოდ გააუმჯობესა, მხოლოდ 0.1-ით და ავიდე 0.75ზე. 
*მესამე რანი "saving all columns and its missing values"*: რადგან ვნახე, რომ მისინგ ველიუების "შენახვამ" დასწავლისას უკეთესი შედეგი გამოიღო, ვივარაუდე, რომ ის ქოლუმები, რომლებსაც ბევრი მისინგ ველიუ ჰქონდათ და ამის გამო ვშლიდი, შესაძლოა, პირიქით, დაგვხმარებოდა დასწავლის პროცესში, ამიტომ თრეშჰოლდი ავწიე 1ზე. ასევე, ფაიფლაინიდან ამოვიღე კორელაციის ფილტრი, რომ ყველა ქოლუმი შემენარჩუნებინა. ამან მომცა უკეთესი შედეგი: 0.79.
*მეოთხე რანი "saving all columns and its missing values + scaler"*: აქამდე არ ვიყენებდი სქეილერს და დავამატე უბრალოდ სტანდარტ-სქეილერი და სქორი ავიდა 0.84მდე, რაც არის ამ ექსპერიმენტის საუკეთესო შედეგი (roc_auc_train = 0.8457 , roc_auc_val = 0.8446)

#model_experiment_Random_Forest_using_transactions
ამ მოდელში გავტესტავ Random Forestის მეთოდს, მაგრამ ჯერ კიდევ დაუმერჯავ დატაზე, მხოლოდ train_transactionების გამოყენებით. 
*პირველი რანი "random forest with standart cleaning method"*: პირველ ვარიანტად დავწერე ყველაზე მარტივი რანდომ ფორესთი, რომელიც მისინგებს ავსებს მოდით/მედიანით და დროპავს ქოლუმებს, რომელშიც მისინგები > 80%. ენქოდერიც ასევე სტანდარტული, უნიკალური<3 ქოლუმებისთის one-hot, და დანარჩენებისთვის WOE. ვალიდაციაზე ავიღე სქორი: 0.9126
*მეორე რანი "" *: აქ დავამატე ანდერსემფლინგი, დაუბალანსებელი დატის გამო. თუმცა ამან 

#missing values:
ჯერ შევამოწმე ეს ნალ ველიუები უფრო ხშირად ხომ არ გვხვდებოდა fraud შემთხვევებში, ვიდრე non_fraudში, ან პირიქით. რადგან მაინც იყო კორელაცია, პირდაპირ ნალების ჩანაცვლებას მოდით ან მედიანით, ვარჩიე რამდენიმე კატეგორად დაყოფა: პირდაპირ დავდროპე სვეტები, სადაც იყო >90%ზე. იმ ქოლუმენბისთვის, სადაც მისინგები იყო 50-90%, ვარჩიე flagების შექმნა, რადგან მაინც მაღალი რიცხვი გამოდიოდა და შესაძლოა რაიმე ფორმით ეგეც დაკავშირებული ყოფილიყო fraudის predictivityსთან. იქ სადაც დაბალი რიცხობრივად ნაკლები გამოდიოდა ნალები და ნაკლებ სავარაუდო იყო, მოეხდინა გავლენა ფრედიქთზე, სტანდარტულად შევცვალე moda/medianებით.
